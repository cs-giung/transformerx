# MMLU

The example demonstrates MMLU evaluation.
```bash
python examples/mmlu/run.py --model meta-llama/Meta-Llama-3-8B
```

## macro-average

| `model`                               | `FP16` | `Q8_0` | `Q7_0` | `Q6_0` | `Q5_0` | `Q4_0` | `Q3_0` |
| :-                                    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    |
| `huggyllama/llama-7b`                 | 0.3205 | 0.3166 | 0.3232 | 0.3202 | 0.3052 | 0.2283 | 0.0044 |
| `meta-llama/Llama-2-7b-chat-hf`       | 0.4688 | 0.4690 | 0.4668 | 0.4700 | 0.4495 | 0.3688 | 0.0000 |
| `meta-llama/Llama-2-7b-hf`            | 0.3941 | 0.3915 | 0.3958 | 0.3813 | 0.3941 | 0.2817 | 0.0133 |
| `meta-llama/Meta-Llama-3-8B-Instruct` | 0.6700 | 0.6691 | 0.6718 | 0.6575 | 0.6411 | 0.5246 | 0.0011 |
| `meta-llama/Meta-Llama-3-8B`          | 0.6377 | 0.6352 | 0.6383 | 0.6267 | 0.6145 | 0.4603 | 0.0016 |
| `microsoft/Phi-3-medium-4k-instruct`  | 0.7675 | 0.7622 | 0.7567 | 0.7673 | 0.7519 | 0.6007 | 0.0017 |
| `microsoft/Phi-3-mini-4k-instruct`    | 0.6622 | 0.6625 | 0.6688 | 0.6650 | 0.6332 | 0.4106 | 0.0050 |
| `mistralai/Mistral-7B-Instruct-v0.1`  | 0.5452 | 0.5450 | 0.5469 | 0.5457 | 0.5482 | 0.5304 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.2`  | 0.6165 | 0.6155 | 0.6144 | 0.6139 | 0.6193 | 0.5795 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.3`  | 0.6170 | 0.6139 | 0.6146 | 0.6161 | 0.6139 | 0.5734 | 0.0003 |

## micro-average

| `model`                               | `FP16` | `Q8_0` | `Q7_0` | `Q6_0` | `Q5_0` | `Q4_0` | `Q3_0` |
| :-                                    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    |
| `huggyllama/llama-7b`                 | 0.3050 | 0.3044 | 0.3089 | 0.3207 | 0.2978 | 0.2162 | 0.0033 |
| `meta-llama/Llama-2-7b-chat-hf`       | 0.4572 | 0.4566 | 0.4553 | 0.4585 | 0.4415 | 0.3690 | 0.0000 |
| `meta-llama/Llama-2-7b-hf`            | 0.3703 | 0.3710 | 0.3730 | 0.3553 | 0.3690 | 0.2600 | 0.0118 |
| `meta-llama/Meta-Llama-3-8B-Instruct` | 0.6408 | 0.6388 | 0.6427 | 0.6303 | 0.6133 | 0.5127 | 0.0007 |
| `meta-llama/Meta-Llama-3-8B`          | 0.6094 | 0.6074 | 0.6140 | 0.5976 | 0.5931 | 0.4481 | 0.0013 |
| `microsoft/Phi-3-medium-4k-instruct`  | 0.7740 | 0.7734 | 0.7681 | 0.7753 | 0.7590 | 0.5813 | 0.0020 |
| `microsoft/Phi-3-mini-4k-instruct`    | 0.6662 | 0.6669 | 0.6721 | 0.6656 | 0.6381 | 0.4167 | 0.0046 |
| `mistralai/Mistral-7B-Instruct-v0.1`  | 0.5284 | 0.5265 | 0.5278 | 0.5265 | 0.5291 | 0.5147 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.2`  | 0.6035 | 0.6055 | 0.6029 | 0.5996 | 0.6029 | 0.5617 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.3`  | 0.5983 | 0.5957 | 0.5983 | 0.5931 | 0.5963 | 0.5513 | 0.0007 |

# Reasoning

The example demonstrates reasoning tasks.
```bash
python examples/mmlu/run_reasoning.py --model meta-llama/Meta-Llama-3-8B
```

## ARC-C

| `model`                               | `FP16` | `Q8_0` | `Q7_0` | `Q6_0` | `Q5_0` | `Q4_0` | `Q3_0` |
| :-                                    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    |
| `huggyllama/llama-7b`                 | 0.3278 | 0.3378 | 0.3478 | 0.3445 | 0.2408 | 0.2074 | 0.0033 |
| `meta-llama/Llama-2-7b-chat-hf`       | 0.5217 | 0.5184 | 0.5251 | 0.5284 | 0.5151 | 0.4281 | 0.0000 |
| `meta-llama/Llama-2-7b-hf`            | 0.3946 | 0.4147 | 0.4080 | 0.3779 | 0.3913 | 0.3244 | 0.0201 |
| `meta-llama/Meta-Llama-3-8B-Instruct` | 0.8194 | 0.8161 | 0.8161 | 0.8127 | 0.7893 | 0.6355 | 0.0000 |
| `meta-llama/Meta-Llama-3-8B`          | 0.8060 | 0.8094 | 0.7960 | 0.7993 | 0.7425 | 0.5284 | 0.0000 |
| `microsoft/Phi-3-medium-4k-instruct`  | 0.9097 | 0.9097 | 0.8997 | 0.8997 | 0.8963 | 0.8796 | 0.0000 |
| `microsoft/Phi-3-mini-4k-instruct`    | 0.8763 | 0.8729 | 0.8763 | 0.8696 | 0.8662 | 0.7960 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.1`  | 0.6856 | 0.6890 | 0.6890 | 0.6856 | 0.6990 | 0.6455 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.2`  | 0.7559 | 0.7592 | 0.7592 | 0.7659 | 0.7391 | 0.7157 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.3`  | 0.8027 | 0.7993 | 0.7960 | 0.7860 | 0.7893 | 0.7157 | 0.0000 |

## ARC-E

| `model`                               | `FP16` | `Q8_0` | `Q7_0` | `Q6_0` | `Q5_0` | `Q4_0` | `Q3_0` |
| :-                                    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    |
| `huggyllama/llama-7b`                 | 0.4053 | 0.4105 | 0.4333 | 0.4526 | 0.3246 | 0.2386 | 0.0000 |
| `meta-llama/Llama-2-7b-chat-hf`       | 0.7333 | 0.7351 | 0.7316 | 0.7456 | 0.7211 | 0.6035 | 0.0035 |
| `meta-llama/Llama-2-7b-hf`            | 0.5895 | 0.5825 | 0.5860 | 0.5474 | 0.5246 | 0.3018 | 0.0193 |
| `meta-llama/Meta-Llama-3-8B-Instruct` | 0.9175 | 0.9140 | 0.9158 | 0.9140 | 0.9018 | 0.7965 | 0.0000 |
| `meta-llama/Meta-Llama-3-8B`          | 0.8842 | 0.8807 | 0.8877 | 0.8825 | 0.8561 | 0.7158 | 0.0035 |
| `microsoft/Phi-3-medium-4k-instruct`  | 0.9649 | 0.9667 | 0.9596 | 0.9614 | 0.9579 | 0.9474 | 0.0035 |
| `microsoft/Phi-3-mini-4k-instruct`    | 0.9526 | 0.9509 | 0.9491 | 0.9509 | 0.9456 | 0.9123 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.1`  | 0.8281 | 0.8281 | 0.8263 | 0.8316 | 0.8228 | 0.8158 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.2`  | 0.8509 | 0.8509 | 0.8491 | 0.8491 | 0.8439 | 0.8351 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.3`  | 0.8807 | 0.8772 | 0.8789 | 0.8842 | 0.8667 | 0.8368 | 0.0000 |

## CommonsenseQA

| `model`                               | `FP16` | `Q8_0` | `Q7_0` | `Q6_0` | `Q5_0` | `Q4_0` | `Q3_0` |
| :-                                    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    |
| `huggyllama/llama-7b`                 | 0.1294 | 0.1351 | 0.1785 | 0.1589 | 0.0762 | 0.1794 | 0.0000 |
| `meta-llama/Llama-2-7b-chat-hf`       | 0.5676 | 0.5651 | 0.5725 | 0.5643 | 0.5610 | 0.3898 | 0.0000 |
| `meta-llama/Llama-2-7b-hf`            | 0.2072 | 0.2195 | 0.2244 | 0.1843 | 0.2596 | 0.2416 | 0.0229 |
| `meta-llama/Meta-Llama-3-8B-Instruct` | 0.7453 | 0.7453 | 0.7412 | 0.7371 | 0.7240 | 0.6249 | 0.0033 |
| `meta-llama/Meta-Llama-3-8B`          | 0.6962 | 0.7002 | 0.6880 | 0.6937 | 0.6437 | 0.4685 | 0.0000 |
| `microsoft/Phi-3-medium-4k-instruct`  | 0.7871 | 0.7887 | 0.7887 | 0.7821 | 0.7731 | 0.7477 | 0.0025 |
| `microsoft/Phi-3-mini-4k-instruct`    | 0.7592 | 0.7592 | 0.7535 | 0.7707 | 0.7387 | 0.6675 | 0.0016 |
| `mistralai/Mistral-7B-Instruct-v0.1`  | 0.6593 | 0.6642 | 0.6560 | 0.6519 | 0.6536 | 0.6183 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.2`  | 0.6749 | 0.6757 | 0.6708 | 0.6757 | 0.6765 | 0.6355 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.3`  | 0.7002 | 0.7068 | 0.6986 | 0.7068 | 0.6953 | 0.6470 | 0.0000 |

## HellSwag

| `model`                               | `FP16` | `Q8_0` | `Q7_0` | `Q6_0` | `Q5_0` | `Q4_0` | `Q3_0` |
| :-                                    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    |
| `huggyllama/llama-7b`                 | 0.2700 | 0.2673 | 0.2759 | 0.2816 | 0.2742 | 0.2077 | 0.0002 |
| `meta-llama/Llama-2-7b-chat-hf`       | 0.4035 | 0.4098 | 0.4133 | 0.3642 | 0.4662 | 0.3262 | 0.0009 |
| `meta-llama/Llama-2-7b-hf`            | 0.1182 | 0.1291 | 0.1236 | 0.0937 | 0.1558 | 0.2323 | 0.0011 |
| `meta-llama/Meta-Llama-3-8B-Instruct` | 0.7469 | 0.7480 | 0.7432 | 0.7499 | 0.7297 | 0.5536 | 0.0000 |
| `meta-llama/Meta-Llama-3-8B`          | 0.6020 | 0.5967 | 0.5957 | 0.5667 | 0.4594 | 0.2464 | 0.0009 |
| `microsoft/Phi-3-medium-4k-instruct`  | 0.8899 | 0.8878 | 0.8910 | 0.8879 | 0.8698 | 0.7865 | 0.0020 |
| `microsoft/Phi-3-mini-4k-instruct`    | 0.8182 | 0.8178 | 0.8146 | 0.8128 | 0.8075 | 0.6247 | 0.0014 |
| `mistralai/Mistral-7B-Instruct-v0.1`  | 0.5960 | 0.5967 | 0.5992 | 0.6002 | 0.5933 | 0.5560 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.2`  | 0.6500 | 0.6493 | 0.6464 | 0.6578 | 0.6496 | 0.5628 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.3`  | 0.6722 | 0.6713 | 0.6727 | 0.6747 | 0.6597 | 0.5130 | 0.0002 |

## PIQA

| `model`                               | `FP16` | `Q8_0` | `Q7_0` | `Q6_0` | `Q5_0` | `Q4_0` | `Q3_0` |
| :-                                    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    |
| `huggyllama/llama-7b`                 | 0.5185 | 0.5169 | 0.5386 | 0.4973 | 0.5136 | 0.4820 | 0.0000 |
| `meta-llama/Llama-2-7b-chat-hf`       | 0.6692 | 0.6692 | 0.6687 | 0.6779 | 0.6387 | 0.5838 | 0.0000 |
| `meta-llama/Llama-2-7b-hf`            | 0.5566 | 0.5593 | 0.5604 | 0.4227 | 0.5419 | 0.4701 | 0.0076 |
| `meta-llama/Meta-Llama-3-8B-Instruct` | 0.8166 | 0.8161 | 0.8188 | 0.8139 | 0.8112 | 0.7089 | 0.0000 |
| `meta-llama/Meta-Llama-3-8B`          | 0.7644 | 0.7606 | 0.7622 | 0.7758 | 0.6779 | 0.6039 | 0.0000 |
| `microsoft/Phi-3-medium-4k-instruct`  | 0.8999 | 0.9004 | 0.9021 | 0.9015 | 0.8977 | 0.7737 | 0.0033 |
| `microsoft/Phi-3-mini-4k-instruct`    | 0.8411 | 0.8384 | 0.8346 | 0.8395 | 0.8324 | 0.7155 | 0.0005 |
| `mistralai/Mistral-7B-Instruct-v0.1`  | 0.7508 | 0.7535 | 0.7535 | 0.7546 | 0.7579 | 0.7682 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.2`  | 0.7720 | 0.7699 | 0.7737 | 0.7780 | 0.7590 | 0.7530 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.3`  | 0.8058 | 0.8069 | 0.8030 | 0.8058 | 0.8009 | 0.7427 | 0.0005 |
