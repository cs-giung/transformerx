# MMLU (5-shot)

The example demonstrates MMLU evaluation.
```bash
python examples/mmlu/run.py --model microsoft/Phi-3-mini-4k-instruct --shot 5
```

## macro-average

| `model`                               | `FP16` | `Q8_0` | `Q7_0` | `Q6_0` | `Q5_0` | `Q4_0` | `Q3_0` |
| :-                                    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    |
| `huggyllama/llama-7b`                 | 0.3308 | 0.3430 | 0.3289 | 0.3403 | 0.3328 | 0.2597 | 0.0000 |
| `meta-llama/Llama-2-7b-chat-hf`       | 0.4901 | 0.4870 | 0.4874 | 0.4827 | 0.4827 | 0.3946 | 0.0000 |
| `meta-llama/Llama-2-7b-hf`            | 0.4713 | 0.4634 | 0.4584 | 0.4587 | 0.4388 | 0.3769 | 0.0000 |
| `meta-llama/Meta-Llama-3-8B-Instruct` | 0.6528 | 0.6617 | 0.6612 | 0.6621 | 0.6409 | 0.5162 | 0.0000 |
| `meta-llama/Meta-Llama-3-8B`          | 0.6418 | 0.6439 | 0.6490 | 0.6384 | 0.6179 | 0.4186 | 0.0010 |
| `microsoft/Phi-3-medium-4k-instruct`  | 0.7907 | 0.7950 | 0.7903 | 0.7920 | 0.7827 | 0.7477 | 0.0018 |
| `microsoft/Phi-3-mini-4k-instruct`    | 0.7134 | 0.7143 | 0.7068 | 0.7007 | 0.7004 | 0.6171 | 0.0029 |
| `mistral-community/Mistral-7B-v0.2`   | 0.6089 | 0.6194 | 0.6072 | 0.6084 | 0.6060 | 0.5650 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.1`  | 0.5401 | 0.5424 | 0.5339 | 0.5428 | 0.5359 | 0.5237 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.2`  | 0.6092 | 0.6065 | 0.6108 | 0.6162 | 0.6068 | 0.5648 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.3`  | 0.6276 | 0.6279 | 0.6269 | 0.6404 | 0.6307 | 0.5749 | 0.0000 |
| `mistralai/Mistral-7B-v0.1`           | 0.6299 | 0.6281 | 0.6221 | 0.6213 | 0.6209 | 0.5632 | 0.0024 |
| `mistralai/Mistral-7B-v0.3`           | 0.6089 | 0.6194 | 0.6072 | 0.6084 | 0.6060 | 0.5650 | 0.0000 |

## micro-average

| `model`                               | `FP16` | `Q8_0` | `Q7_0` | `Q6_0` | `Q5_0` | `Q4_0` | `Q3_0` |
| :-                                    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    |
| `huggyllama/llama-7b`                 | 0.3364 | 0.3429 | 0.3325 | 0.3429 | 0.3383 | 0.2743 | 0.0000 |
| `meta-llama/Llama-2-7b-chat-hf`       | 0.4703 | 0.4703 | 0.4709 | 0.4677 | 0.4624 | 0.3926 | 0.0000 |
| `meta-llama/Llama-2-7b-hf`            | 0.4526 | 0.4442 | 0.4415 | 0.4455 | 0.4252 | 0.3651 | 0.0000 |
| `meta-llama/Meta-Llama-3-8B-Instruct` | 0.6401 | 0.6453 | 0.6453 | 0.6440 | 0.6270 | 0.5042 | 0.0000 |
| `meta-llama/Meta-Llama-3-8B`          | 0.6303 | 0.6303 | 0.6375 | 0.6218 | 0.6107 | 0.4121 | 0.0007 |
| `microsoft/Phi-3-medium-4k-instruct`  | 0.8008 | 0.8060 | 0.8014 | 0.8073 | 0.7923 | 0.7440 | 0.0013 |
| `microsoft/Phi-3-mini-4k-instruct`    | 0.7146 | 0.7126 | 0.7080 | 0.7048 | 0.7015 | 0.6061 | 0.0020 |
| `mistral-community/Mistral-7B-v0.2`   | 0.5976 | 0.6048 | 0.5924 | 0.5944 | 0.5898 | 0.5460 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.1`  | 0.5258 | 0.5271 | 0.5219 | 0.5278 | 0.5206 | 0.5101 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.2`  | 0.6029 | 0.6029 | 0.6074 | 0.6088 | 0.6029 | 0.5624 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.3`  | 0.6172 | 0.6166 | 0.6199 | 0.6231 | 0.6218 | 0.5604 | 0.0000 |
| `mistralai/Mistral-7B-v0.1`           | 0.6114 | 0.6088 | 0.6048 | 0.6035 | 0.6068 | 0.5434 | 0.0020 |
| `mistralai/Mistral-7B-v0.3`           | 0.5976 | 0.6048 | 0.5924 | 0.5944 | 0.5898 | 0.5460 | 0.0000 |

# MMLU (0-shot)

The example demonstrates MMLU evaluation.
```bash
python examples/mmlu/run.py --model microsoft/Phi-3-mini-4k-instruct --shot 0
```

## macro-average

| `model`                               | `FP16` | `Q8_0` | `Q7_0` | `Q6_0` | `Q5_0` | `Q4_0` | `Q3_0` |
| :-                                    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    |
| `huggyllama/llama-7b`                 | 0.3205 | 0.3166 | 0.3232 | 0.3202 | 0.3052 | 0.2283 | 0.0044 |
| `meta-llama/Llama-2-7b-chat-hf`       | 0.4688 | 0.4690 | 0.4668 | 0.4700 | 0.4495 | 0.3688 | 0.0000 |
| `meta-llama/Llama-2-7b-hf`            | 0.3941 | 0.3915 | 0.3958 | 0.3813 | 0.3941 | 0.2817 | 0.0133 |
| `meta-llama/Meta-Llama-3-8B-Instruct` | 0.6700 | 0.6691 | 0.6718 | 0.6575 | 0.6411 | 0.5246 | 0.0011 |
| `meta-llama/Meta-Llama-3-8B`          | 0.6377 | 0.6352 | 0.6383 | 0.6267 | 0.6145 | 0.4603 | 0.0016 |
| `microsoft/Phi-3-medium-4k-instruct`  | 0.7675 | 0.7622 | 0.7567 | 0.7673 | 0.7519 | 0.6007 | 0.0017 |
| `microsoft/Phi-3-mini-4k-instruct`    | 0.6622 | 0.6625 | 0.6688 | 0.6650 | 0.6332 | 0.4106 | 0.0050 |
| `mistral-community/Mistral-7B-v0.2`   | 0.5410 | 0.5405 | 0.5440 | 0.5523 | 0.5066 | 0.5044 | 0.0009 |
| `mistralai/Mistral-7B-Instruct-v0.1`  | 0.5452 | 0.5450 | 0.5469 | 0.5457 | 0.5482 | 0.5304 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.2`  | 0.6165 | 0.6155 | 0.6144 | 0.6139 | 0.6193 | 0.5795 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.3`  | 0.6170 | 0.6139 | 0.6146 | 0.6161 | 0.6139 | 0.5734 | 0.0003 |
| `mistralai/Mistral-7B-v0.1`           | 0.5621 | 0.5542 | 0.5625 | 0.5483 | 0.5869 | 0.5115 | 0.0000 |
| `mistralai/Mistral-7B-v0.3`           | 0.5410 | 0.5405 | 0.5440 | 0.5523 | 0.5066 | 0.5044 | 0.0009 |

## micro-average

| `model`                               | `FP16` | `Q8_0` | `Q7_0` | `Q6_0` | `Q5_0` | `Q4_0` | `Q3_0` |
| :-                                    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    |
| `huggyllama/llama-7b`                 | 0.3050 | 0.3044 | 0.3089 | 0.3207 | 0.2978 | 0.2162 | 0.0033 |
| `meta-llama/Llama-2-7b-chat-hf`       | 0.4572 | 0.4566 | 0.4553 | 0.4585 | 0.4415 | 0.3690 | 0.0000 |
| `meta-llama/Llama-2-7b-hf`            | 0.3703 | 0.3710 | 0.3730 | 0.3553 | 0.3690 | 0.2600 | 0.0118 |
| `meta-llama/Meta-Llama-3-8B-Instruct` | 0.6408 | 0.6388 | 0.6427 | 0.6303 | 0.6133 | 0.5127 | 0.0007 |
| `meta-llama/Meta-Llama-3-8B`          | 0.6094 | 0.6074 | 0.6140 | 0.5976 | 0.5931 | 0.4481 | 0.0013 |
| `microsoft/Phi-3-medium-4k-instruct`  | 0.7740 | 0.7734 | 0.7681 | 0.7753 | 0.7590 | 0.5813 | 0.0020 |
| `microsoft/Phi-3-mini-4k-instruct`    | 0.6662 | 0.6669 | 0.6721 | 0.6656 | 0.6381 | 0.4167 | 0.0046 |
| `mistral-community/Mistral-7B-v0.2`   | 0.5297 | 0.5297 | 0.5304 | 0.5369 | 0.4977 | 0.4749 | 0.0013 |
| `mistralai/Mistral-7B-Instruct-v0.1`  | 0.5284 | 0.5265 | 0.5278 | 0.5265 | 0.5291 | 0.5147 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.2`  | 0.6035 | 0.6055 | 0.6029 | 0.5996 | 0.6029 | 0.5617 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.3`  | 0.5983 | 0.5957 | 0.5983 | 0.5931 | 0.5963 | 0.5513 | 0.0007 |
| `mistralai/Mistral-7B-v0.1`           | 0.5519 | 0.5434 | 0.5513 | 0.5408 | 0.5689 | 0.5121 | 0.0000 |
| `mistralai/Mistral-7B-v0.3`           | 0.5297 | 0.5297 | 0.5304 | 0.5369 | 0.4977 | 0.4749 | 0.0013 |

# Reasoning (0-shot)

The example demonstrates reasoning tasks.
```bash
python examples/mmlu/run_reasoning.py --model microsoft/Phi-3-mini-4k-instruct
```

## ARC-C

| `model`                               | `FP16` | `Q8_0` | `Q7_0` | `Q6_0` | `Q5_0` | `Q4_0` | `Q3_0` |
| :-                                    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    |
| `huggyllama/llama-7b`                 | 0.3278 | 0.3378 | 0.3478 | 0.3445 | 0.2408 | 0.2074 | 0.0033 |
| `meta-llama/Llama-2-7b-chat-hf`       | 0.5217 | 0.5184 | 0.5251 | 0.5284 | 0.5151 | 0.4281 | 0.0000 |
| `meta-llama/Llama-2-7b-hf`            | 0.3946 | 0.4147 | 0.4080 | 0.3779 | 0.3913 | 0.3244 | 0.0201 |
| `meta-llama/Meta-Llama-3-8B-Instruct` | 0.8194 | 0.8161 | 0.8161 | 0.8127 | 0.7893 | 0.6355 | 0.0000 |
| `meta-llama/Meta-Llama-3-8B`          | 0.8060 | 0.8094 | 0.7960 | 0.7993 | 0.7425 | 0.5284 | 0.0000 |
| `microsoft/Phi-3-medium-4k-instruct`  | 0.9097 | 0.9097 | 0.8997 | 0.8997 | 0.8963 | 0.8796 | 0.0000 |
| `microsoft/Phi-3-mini-4k-instruct`    | 0.8763 | 0.8729 | 0.8763 | 0.8696 | 0.8662 | 0.7960 | 0.0000 |
| `mistral-community/Mistral-7B-v0.2`   | 0.7592 | 0.7559 | 0.7592 | 0.7625 | 0.7458 | 0.6455 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.1`  | 0.6856 | 0.6890 | 0.6890 | 0.6856 | 0.6990 | 0.6455 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.2`  | 0.7559 | 0.7592 | 0.7592 | 0.7659 | 0.7391 | 0.7157 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.3`  | 0.8027 | 0.7993 | 0.7960 | 0.7860 | 0.7893 | 0.7157 | 0.0000 |
| `mistralai/Mistral-7B-v0.1`           | 0.7391 | 0.7391 | 0.7458 | 0.7291 | 0.7358 | 0.6421 | 0.0000 |
| `mistralai/Mistral-7B-v0.3`           | 0.7592 | 0.7559 | 0.7592 | 0.7625 | 0.7458 | 0.6455 | 0.0000 |

## ARC-E

| `model`                               | `FP16` | `Q8_0` | `Q7_0` | `Q6_0` | `Q5_0` | `Q4_0` | `Q3_0` |
| :-                                    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    |
| `huggyllama/llama-7b`                 | 0.4053 | 0.4105 | 0.4333 | 0.4526 | 0.3246 | 0.2386 | 0.0000 |
| `meta-llama/Llama-2-7b-chat-hf`       | 0.7333 | 0.7351 | 0.7316 | 0.7456 | 0.7211 | 0.6035 | 0.0035 |
| `meta-llama/Llama-2-7b-hf`            | 0.5895 | 0.5825 | 0.5860 | 0.5474 | 0.5246 | 0.3018 | 0.0193 |
| `meta-llama/Meta-Llama-3-8B-Instruct` | 0.9175 | 0.9140 | 0.9158 | 0.9140 | 0.9018 | 0.7965 | 0.0000 |
| `meta-llama/Meta-Llama-3-8B`          | 0.8842 | 0.8807 | 0.8877 | 0.8825 | 0.8561 | 0.7158 | 0.0035 |
| `microsoft/Phi-3-medium-4k-instruct`  | 0.9649 | 0.9667 | 0.9596 | 0.9614 | 0.9579 | 0.9474 | 0.0035 |
| `microsoft/Phi-3-mini-4k-instruct`    | 0.9526 | 0.9509 | 0.9491 | 0.9509 | 0.9456 | 0.9123 | 0.0000 |
| `mistral-community/Mistral-7B-v0.2`   | 0.8719 | 0.8684 | 0.8684 | 0.8684 | 0.8614 | 0.8140 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.1`  | 0.8281 | 0.8281 | 0.8263 | 0.8316 | 0.8228 | 0.8158 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.2`  | 0.8509 | 0.8509 | 0.8491 | 0.8491 | 0.8439 | 0.8351 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.3`  | 0.8807 | 0.8772 | 0.8789 | 0.8842 | 0.8667 | 0.8368 | 0.0000 |
| `mistralai/Mistral-7B-v0.1`           | 0.8561 | 0.8509 | 0.8614 | 0.8632 | 0.8526 | 0.8193 | 0.0000 |
| `mistralai/Mistral-7B-v0.3`           | 0.8719 | 0.8684 | 0.8684 | 0.8684 | 0.8614 | 0.8140 | 0.0000 |

## CommonsenseQA

| `model`                               | `FP16` | `Q8_0` | `Q7_0` | `Q6_0` | `Q5_0` | `Q4_0` | `Q3_0` |
| :-                                    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    |
| `huggyllama/llama-7b`                 | 0.1294 | 0.1351 | 0.1785 | 0.1589 | 0.0762 | 0.1794 | 0.0000 |
| `meta-llama/Llama-2-7b-chat-hf`       | 0.5676 | 0.5651 | 0.5725 | 0.5643 | 0.5610 | 0.3898 | 0.0000 |
| `meta-llama/Llama-2-7b-hf`            | 0.2072 | 0.2195 | 0.2244 | 0.1843 | 0.2596 | 0.2416 | 0.0229 |
| `meta-llama/Meta-Llama-3-8B-Instruct` | 0.7453 | 0.7453 | 0.7412 | 0.7371 | 0.7240 | 0.6249 | 0.0033 |
| `meta-llama/Meta-Llama-3-8B`          | 0.6962 | 0.7002 | 0.6880 | 0.6937 | 0.6437 | 0.4685 | 0.0000 |
| `microsoft/Phi-3-medium-4k-instruct`  | 0.7871 | 0.7887 | 0.7887 | 0.7821 | 0.7731 | 0.7477 | 0.0025 |
| `microsoft/Phi-3-mini-4k-instruct`    | 0.7592 | 0.7592 | 0.7535 | 0.7707 | 0.7387 | 0.6675 | 0.0016 |
| `mistral-community/Mistral-7B-v0.2`   | 0.6749 | 0.6740 | 0.6740 | 0.6790 | 0.6568 | 0.5299 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.1`  | 0.6593 | 0.6642 | 0.6560 | 0.6519 | 0.6536 | 0.6183 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.2`  | 0.6749 | 0.6757 | 0.6708 | 0.6757 | 0.6765 | 0.6355 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.3`  | 0.7002 | 0.7068 | 0.6986 | 0.7068 | 0.6953 | 0.6470 | 0.0000 |
| `mistralai/Mistral-7B-v0.1`           | 0.6773 | 0.6814 | 0.6773 | 0.6732 | 0.6478 | 0.5799 | 0.0000 |
| `mistralai/Mistral-7B-v0.3`           | 0.6749 | 0.6740 | 0.6740 | 0.6790 | 0.6568 | 0.5299 | 0.0000 |

## HellSwag

| `model`                               | `FP16` | `Q8_0` | `Q7_0` | `Q6_0` | `Q5_0` | `Q4_0` | `Q3_0` |
| :-                                    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    |
| `huggyllama/llama-7b`                 | 0.2700 | 0.2673 | 0.2759 | 0.2816 | 0.2742 | 0.2077 | 0.0002 |
| `meta-llama/Llama-2-7b-chat-hf`       | 0.4035 | 0.4098 | 0.4133 | 0.3642 | 0.4662 | 0.3262 | 0.0009 |
| `meta-llama/Llama-2-7b-hf`            | 0.1182 | 0.1291 | 0.1236 | 0.0937 | 0.1558 | 0.2323 | 0.0011 |
| `meta-llama/Meta-Llama-3-8B-Instruct` | 0.7469 | 0.7480 | 0.7432 | 0.7499 | 0.7297 | 0.5536 | 0.0000 |
| `meta-llama/Meta-Llama-3-8B`          | 0.6020 | 0.5967 | 0.5957 | 0.5667 | 0.4594 | 0.2464 | 0.0009 |
| `microsoft/Phi-3-medium-4k-instruct`  | 0.8899 | 0.8878 | 0.8910 | 0.8879 | 0.8698 | 0.7865 | 0.0020 |
| `microsoft/Phi-3-mini-4k-instruct`    | 0.8182 | 0.8178 | 0.8146 | 0.8128 | 0.8075 | 0.6247 | 0.0014 |
| `mistral-community/Mistral-7B-v0.2`   | 0.5244 | 0.5306 | 0.5149 | 0.5191 | 0.4735 | 0.2884 | 0.0001 |
| `mistralai/Mistral-7B-Instruct-v0.1`  | 0.5960 | 0.5967 | 0.5992 | 0.6002 | 0.5933 | 0.5560 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.2`  | 0.6500 | 0.6493 | 0.6464 | 0.6578 | 0.6496 | 0.5628 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.3`  | 0.6722 | 0.6713 | 0.6727 | 0.6747 | 0.6597 | 0.5130 | 0.0002 |
| `mistralai/Mistral-7B-v0.1`           | 0.5213 | 0.5182 | 0.5112 | 0.5485 | 0.4921 | 0.3590 | 0.0000 |
| `mistralai/Mistral-7B-v0.3`           | 0.5244 | 0.5306 | 0.5149 | 0.5191 | 0.4735 | 0.2884 | 0.0001 |

## PIQA

| `model`                               | `FP16` | `Q8_0` | `Q7_0` | `Q6_0` | `Q5_0` | `Q4_0` | `Q3_0` |
| :-                                    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    | :-:    |
| `huggyllama/llama-7b`                 | 0.5185 | 0.5169 | 0.5386 | 0.4973 | 0.5136 | 0.4820 | 0.0000 |
| `meta-llama/Llama-2-7b-chat-hf`       | 0.6692 | 0.6692 | 0.6687 | 0.6779 | 0.6387 | 0.5838 | 0.0000 |
| `meta-llama/Llama-2-7b-hf`            | 0.5566 | 0.5593 | 0.5604 | 0.4227 | 0.5419 | 0.4701 | 0.0076 |
| `meta-llama/Meta-Llama-3-8B-Instruct` | 0.8166 | 0.8161 | 0.8188 | 0.8139 | 0.8112 | 0.7089 | 0.0000 |
| `meta-llama/Meta-Llama-3-8B`          | 0.7644 | 0.7606 | 0.7622 | 0.7758 | 0.6779 | 0.6039 | 0.0000 |
| `microsoft/Phi-3-medium-4k-instruct`  | 0.8999 | 0.9004 | 0.9021 | 0.9015 | 0.8977 | 0.7737 | 0.0033 |
| `microsoft/Phi-3-mini-4k-instruct`    | 0.8411 | 0.8384 | 0.8346 | 0.8395 | 0.8324 | 0.7155 | 0.0005 |
| `mistral-community/Mistral-7B-v0.2`   | 0.7693 | 0.7693 | 0.7688 | 0.7693 | 0.7388 | 0.6567 | 0.0011 |
| `mistralai/Mistral-7B-Instruct-v0.1`  | 0.7508 | 0.7535 | 0.7535 | 0.7546 | 0.7579 | 0.7682 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.2`  | 0.7720 | 0.7699 | 0.7737 | 0.7780 | 0.7590 | 0.7530 | 0.0000 |
| `mistralai/Mistral-7B-Instruct-v0.3`  | 0.8058 | 0.8069 | 0.8030 | 0.8058 | 0.8009 | 0.7427 | 0.0005 |
| `mistralai/Mistral-7B-v0.1`           | 0.8003 | 0.8041 | 0.8030 | 0.7971 | 0.7677 | 0.7160 | 0.0000 |
| `mistralai/Mistral-7B-v0.3`           | 0.7693 | 0.7693 | 0.7688 | 0.7693 | 0.7388 | 0.6567 | 0.0011 |
